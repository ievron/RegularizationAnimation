# Why does L1 regularization induce sparse models?

Many illustrate this using the least squares problem with a norm constraint, which is an equivalent problem to the regularized least squares problem.
The least squares level sets are drawn next to the different unit "circles".

I prepared a cool animation which I believe makes it even clearer than the static image :)

![The outcome](https://github.com/ievron/RegularizationAnimation/blob/main/Regularization.gif?raw=true)

## Other helpful resources
- [Youtube: Sparsity and the L1 norm by Steve Brunton](https://www.youtube.com/watch?v=76B5cMEZA4Y&feature=youtu.be&ab_channel=SteveBrunton)
- [Sam Petulla's interactive demo](https://stats.stackexchange.com/questions/45643/why-l1-norm-for-sparse-models/45644#45644)
- [Mathematical explanations on CrossValidated](https://stats.stackexchange.com/questions/45643/why-l1-norm-for-sparse-models/45644)
